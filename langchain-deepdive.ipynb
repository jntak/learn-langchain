{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81228a4e-5f97-442f-bfa5-f026e88762b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Desktop\\joshua ntak\\projects\\langchain-qa-app\n"
     ]
    }
   ],
   "source": [
    "!cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56c3a526-24df-4f29-8570-d125cf4883f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Joshua Ntak\n",
      " Volume Serial Number is 8678-7943\n",
      "\n",
      " Directory of C:\\Users\\PC\\Desktop\\joshua ntak\\projects\\langchain-qa-app\n",
      "\n",
      "21-Sep-25  03:50    <DIR>          .\n",
      "21-Sep-25  03:50    <DIR>          ..\n",
      "19-Sep-25  23:24               295 .env\n",
      "20-Sep-25  09:05                27 .gitignore\n",
      "20-Sep-25  09:07    <DIR>          .ipynb_checkpoints\n",
      "21-Sep-25  03:50             6,506 langchain-qa-app.ipynb\n",
      "               3 File(s)          6,828 bytes\n",
      "               3 Dir(s)  40,302,088,192 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67da018b-9b0c-471a-bc9a-a529615cc46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True) \n",
    "\n",
    "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47e54220-c4dd-4a3b-9570-404bc5dc1dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8408da6b-a1b8-4e3a-b474-23a441856475",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85d5cc1b-a287-4597-b42e-bee8618ddc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__add__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_backwards_compat_tool_calls', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'additional_kwargs', 'construct', 'content', 'copy', 'dict', 'example', 'from_orm', 'get_lc_namespace', 'id', 'invalid_tool_calls', 'is_lc_serializable', 'json', 'lc_attributes', 'lc_id', 'lc_secrets', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'name', 'parse_file', 'parse_obj', 'parse_raw', 'pretty_print', 'pretty_repr', 'response_metadata', 'schema', 'schema_json', 'text', 'to_json', 'to_json_not_implemented', 'tool_calls', 'type', 'update_forward_refs', 'usage_metadata', 'validate']\n"
     ]
    }
   ],
   "source": [
    "response = chat_llm.invoke(\"What is Quantum mechanics, in one sentence\")\n",
    "print(dir(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "044085eb-0a3d-4612-b99a-7d632ed4139b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quantum mechanics is a fundamental theory in physics that describes the physical properties of nature at the scale of atoms and subatomic particles, where energy, momentum, angular momentum, and other quantities are quantized, not continuous.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27e6389a-f4c1-4259-9877-0acbb606e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(ChatGoogleGenerativeAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5ed1619-14ff-4133-ac23-f086a284fcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, let's talk seismic interpretation. The *very* first step, before you even think about horizons or faults, is **data loading and QC (Quality Control).**\n",
      "\n",
      "Think of it like this: you wouldn't start building a house on a shaky foundation, would you? Same principle here. You need to make sure your seismic data is in good shape before you start interpreting anything.\n",
      "\n",
      "Here's what that typically involves:\n",
      "\n",
      "*   **Loading the data:** Getting the seismic volume into your interpretation software. This might involve dealing with SEG-Y files, coordinate systems, and making sure everything is properly georeferenced.\n",
      "*   **Visual inspection:** A thorough visual check of the data. Are there any obvious problems? Things like:\n",
      "    *   **Noise:** Is there excessive noise that might obscure real geological features?\n",
      "    *   **Amplitude issues:** Are there amplitude variations that don't seem geologically plausible? Are there dead traces or sections with poor data quality?\n",
      "    *   **Phase issues:** Is the data zero-phased or minimum-phased? Is the phase consistent throughout the volume?\n",
      "    *   **Polarity:** Is the data properly poled?\n",
      "*   **Basic data conditioning (if needed):** If you spot some issues, you might do some basic data conditioning to improve the data quality. This could involve things like:\n",
      "    *   **Noise reduction filters:** Applying filters to reduce random noise.\n",
      "    *   **Amplitude balancing:** Applying gain functions to balance amplitudes across the volume.\n",
      "    *   **Trace editing:** Removing or interpolating bad traces.\n",
      "\n",
      "**Why is this so important?**\n",
      "\n",
      "Because garbage in, garbage out! If you start interpreting on bad data, you're going to end up with a flawed interpretation. You might pick horizons that aren't real, miss faults, or misinterpret geological features.\n",
      "\n",
      "So, before you even think about picking that first horizon, make sure your data is as clean and reliable as possible. It'll save you a lot of headaches down the road.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    SystemMessage,\n",
    "    HumanMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a Geophysicist, Speak like a seismic interpreter\"),\n",
    "    HumanMessage(content=\"What is the very first step of seismic interpretation\")\n",
    "]\n",
    "\n",
    "\n",
    "response = chat_llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bb4f8a-d43a-4add-92c0-821cecdee58c",
   "metadata": {},
   "source": [
    "# Caching LLM Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192c6154-0ba1-476b-b3ab-ee1efb245f8f",
   "metadata": {},
   "source": [
    "## In-memory Cache "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7727cd4-fca1-45f0-856f-5b48848130e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import langchain_google_genai\n",
    "# help(langchain_google_genai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa5e44c4-404d-4ccb-8f43-42627ddabd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "\n",
    "llm = GoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "72b8e5d3-c2a3-42da-b0a2-154de10bdeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 1.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Governor of Rivers State is Siminalayi Fubara.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "set_llm_cache(InMemoryCache())\n",
    "prompt = \"Who is the Governor of Rivers State\"\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "262ec459-de6c-4c20-a6da-66db3edb5717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Governor of Rivers State is Siminalayi Fubara.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf762e71-e8fd-4129-8e9e-eb0b32934ca3",
   "metadata": {},
   "source": [
    "## SQLite Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad1b3c2b-b675-476a-8de5-a75216f3dce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 12 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The President of the United States of America is **Joe Biden**.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from langchain.cache import SQLiteCache\n",
    "\n",
    "set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))\n",
    "\n",
    "prompt = \"Who is the President of the United States of America\"\n",
    "\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8945a80d-b458-428d-8eee-a2e3c7e96c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The President of the United States of America is **Joe Biden**.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bf2d3a8f-7ac8-467b-8fb2-b31826a4b546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current President of the United States of America is **Joe Biden**.\n"
     ]
    }
   ],
   "source": [
    "# from langchain.globals import set_llm_cache\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "\n",
    "llm_knowledge = GoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    "    temperature=1\n",
    ")\n",
    "print(llm_knowledge.invoke(\"Who is the current President of the United States of America\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74fcd6e-95cb-4072-b653-e9fbb54d2d70",
   "metadata": {},
   "source": [
    "# LLM Streaming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6fcaef2a-f9b4-40d7-9bd5-702668446cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "chat_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "49987b1a-0ce2-48d6-8a76-ac49ca964198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald John Trump was the 45th President of the United States, serving from 2017 to 2021. Before entering politics, he was a businessman and television personality.\n",
      "\n",
      "Born in Queens, New York City, in 1946, Trump graduated from the Wharton School of the University of Pennsylvania with a degree in economics. He then joined his father's real estate and construction firm, Elizabeth Trump and Son, which he later renamed The Trump Organization. Over the decades, he built, renovated, and managed numerous skyscrapers, hotels, casinos, and golf courses. He also hosted the reality television show \"The Apprentice.\"\n",
      "\n",
      "Trump's political career began in 2015 when he announced his candidacy for President of the United States as a Republican. His campaign focused on issues such as immigration, trade, and national security. He won the 2016 presidential election, defeating Hillary Clinton.\n",
      "\n",
      "During his presidency, Trump enacted significant tax cuts, appointed numerous conservative judges, and pursued deregulation policies. He also initiated trade disputes with China and other countries, withdrew the United States from the Trans-Pacific Partnership trade agreement and the Paris Agreement on climate change, and moved the U.S. embassy in Israel to Jerusalem.\n",
      "\n",
      "Trump was impeached twice by the House of Representatives, once in 2019 for abuse of power and obstruction of Congress, and again in 2021 for inciting an insurrection. He was acquitted by the Senate in both trials.\n",
      "\n",
      "Since leaving office, Trump has remained active in politics and continues to be a prominent figure in the Republican Party.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Give me a short biography of President Donald Trump\"\n",
    "\n",
    "for chunk in chat_llm.stream(prompt):\n",
    "    print(chunk.content, end=\"\", flush=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c94985a-305a-4868-92a6-905162708e35",
   "metadata": {},
   "source": [
    "# Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2f143ec9-f4c9-420b-9c16-f63d823c5013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "template = \"\"\"\n",
    "You are an experienced Geophysicist,\n",
    "Explain the following concept: {concept} in only {nos} sentences, but in clear terms\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "\n",
    "prompt = prompt_template.format(concept=\"Seismic-To-Well Tie\", nos=\"three\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "993b1d7c-bbbc-454b-8706-d9742a819686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(prompt):\n",
    "    res = chat_llm.invoke(prompt)\n",
    "    print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c597166d-57dd-40d2-bd76-829439c09cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seismic-to-well tie is the process of correlating seismic data with well log data to accurately determine the depth of subsurface geological formations. This involves creating a synthetic seismogram from well logs and matching it to the real seismic data, allowing geoscientists to calibrate seismic reflections to specific geological layers encountered in the well. The result is a more accurate interpretation of the seismic data, leading to better reservoir characterization and drilling decisions.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = GoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1265b462-285d-461d-ba5e-98ed05397705",
   "metadata": {},
   "source": [
    " # ChatPrompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6592aee9-7725-43ab-a137-ce898db126e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Respond only in JSON fomat', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Give top 10 countries in the world with lowest cost of living', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content='Respond only in JSON fomat'),\n",
    "        HumanMessagePromptTemplate.from_template(\"Give top {n} countries in the world with {degree} cost of living\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(n=\"10\", degree=\"lowest\")\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "be27e2d8-ea87-4df2-bd4a-a6d725392717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"top_10_countries_lowest_cost_of_living\": [\n",
      "    {\n",
      "      \"rank\": 1,\n",
      "      \"country\": \"Pakistan\"\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 2,\n",
      "      \"country\": \"Nepal\"\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 3,\n",
      "      \"country\": \"Syria\"\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 4,\n",
      "      \"country\": \"India\"\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 5,\n",
      "      \"country\": \"Afghanistan\"\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 6,\n",
      "      \"country\": \"Bangladesh\"\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 7,\n",
      "      \"country\": \"Egypt\"\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 8,\n",
      "      \"country\": \"North Macedonia\"\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 9,\n",
      "      \"country\": \"Tunisia\"\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 10,\n",
      "      \"country\": \"Algeria\"\n",
      "    }\n",
      "  ],\n",
      "  \"disclaimer\": \"Cost of living can vary significantly within a country depending on the city and lifestyle. These rankings are based on general estimates and may not reflect individual experiences. Data is based on Numbeo's Cost of Living Index (as of October 26, 2023) and is subject to change.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "chat_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "output(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b8c4c4cb-746d-45bf-94f3-52a8261518d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"top_10_countries_highest_cost_of_living\": [\n",
      "    {\n",
      "      \"rank\": 1,\n",
      "      \"country\": \"Bermuda\"\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 2,\n",
      "      \"country\": \"Switzerland\"\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 3,\n",
      "      \"country\": \"Cayman Islands\"\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 4,\n",
      "      \"country\": \"Bahamas\"\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 5,\n",
      "      \"country\": \"Singapore\"\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 6,\n",
      "      \"country\": \"Iceland\"\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 7,\n",
      "      \"country\": \"Jersey\"\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 8,\n",
      "      \"country\": \"Luxembourg\"\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 9,\n",
      "      \"country\": \"Israel\"\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 10,\n",
      "      \"country\": \"Hong Kong\"\n",
      "    }\n",
      "  ],\n",
      "  \"disclaimer\": \"Cost of living rankings can vary depending on the source and methodology used. This list is based on commonly cited indices and reports, but may not be definitive.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "messages = chat_template.format_messages(n=\"10\", degree=\"highest\")\n",
    "output(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6407cc93-e61e-4f88-a46b-de01fb3ef556",
   "metadata": {},
   "source": [
    "# Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46268e08-3f06-4f91-996d-ebd8c43f2d7f",
   "metadata": {},
   "source": [
    "## Simple Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ef921663-0d2f-4eaa-a9e0-98dbf94d3cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What concept do you want to learn about?:  Petrophysical Analysis\n",
      "In how many paragraphs do you want this?  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "As an experienced geophysicist, I see Petrophysical Analysis as the critical bridge between our subsurface measurements and the actual reservoir properties. At its core, it's the quantitative study of rock and fluid properties within a reservoir, primarily using well log data, core samples, and sometimes seismic attributes. Its main objective is to determine how much fluid a rock can hold (porosity), how easily fluids can flow through it (permeability), and what types and proportions of fluids (oil, gas, water) are present. This analysis provides the fundamental understanding of the reservoir's storage and flow capacity.\n",
      "\n",
      "The process typically involves integrating and interpreting various data sources. Well logs, which are continuous measurements of physical properties down a borehole (like resistivity, density, neutron, and sonic), are the primary input. These logs are calibrated and validated using direct measurements from core samples, which provide ground truth for porosity, permeability, and fluid saturations. Petrophysicists then apply sophisticated models and algorithms to correct for environmental effects, identify lithology, quantify shale volume, calculate effective porosity, and determine water and hydrocarbon saturations, often accounting for complex rock-fluid interactions.\n",
      "\n",
      "Ultimately, petrophysical analysis is indispensable for robust reservoir characterization and modeling. The derived properties are crucial for accurately estimating hydrocarbon volumes (reserves), designing optimal well completion and production strategies, and making informed decisions about field development and economic viability. It allows us to understand reservoir heterogeneity, predict fluid movement, and assess the overall potential of a discovery. Without sound petrophysical analysis, our ability to effectively evaluate and manage subsurface resources would be severely limited, making it a cornerstone of modern exploration and production.\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "You are an experienced Geophysicist,\n",
    "Explain the following concept: {concept} in only {nos} paragraphs, but in clear terms\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "chat_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "\n",
    "\n",
    "chain = prompt_template | chat_llm | StrOutputParser()\n",
    "\n",
    "\n",
    "concept = input(\"What concept do you want to learn about?: \")\n",
    "paragraphs = input(\"In how many paragraphs do you want this? \")\n",
    "\n",
    "print(\"=\" * 100)\n",
    "output = chain.invoke({\"concept\": concept, \"nos\": paragraphs})\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "85013cb1-8391-421f-bb4e-e970fcc8d8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGoogleGenerativeAI(model='models/gemini-2.0-flash', google_api_key=SecretStr('**********'), temperature=0.0, max_retries=2, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000021990A9CBE0>, default_metadata=(), model_kwargs={})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d818efe5-3953-402f-8de5-115f103af2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Which country?:  Brazil and Canada\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "*   **Brazil:** Brasília\n",
      "*   **Canada:** Ottawa\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "What is the captal of {country}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "country = input(\"Which country?: \")\n",
    "\n",
    "print(\"=\" * 100)\n",
    "output = chain.invoke(country)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516e6178-987a-4545-859d-6aeb6b06a869",
   "metadata": {},
   "source": [
    "## Sequential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3ac24b31-06ed-4727-bd35-9e100a509ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imaginez que vous laissiez tomber un caillou dans un étang calme. Vous voyez des ronds dans l'eau, n'est-ce pas ?\n",
      "\n",
      "Les ondes sismiques sont comme ces ronds dans l'eau, mais elles se produisent sous terre lors d'un tremblement de terre, d'une éruption volcanique, ou même d'une grosse explosion !\n",
      "\n",
      "Au lieu de l'eau, ces ondes se propagent à travers la Terre. Elles transportent l'énergie loin de l'endroit où le \"caillou\" (le tremblement de terre) s'est produit. Nous utilisons des instruments spéciaux pour détecter ces ondes, en apprendre davantage sur l'intérieur de la Terre et déterminer la force du tremblement de terre.\n",
      "\n",
      "En gros : **Les ondes sismiques sont des vibrations qui se propagent à travers la Terre, causées par des perturbations comme les tremblements de terre.**\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# llm model\n",
    "llm_1 = GoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "llm_2 = GoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    "    temperature=1.2,\n",
    ")\n",
    "\n",
    "# first prompt chain\n",
    "prompt1 = PromptTemplate(\n",
    "    input_variables=[\"concept\"],\n",
    "    template=\"Explain the concept of {concept} in very simple terms.\",\n",
    ")\n",
    "\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# second prompt chain\n",
    "prompt2 = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"Now translate the above explanation to French: {text}\",\n",
    ")\n",
    "\n",
    "chain2 = prompt2 | llm_2 | StrOutputParser()\n",
    "\n",
    "\n",
    "# compose\n",
    "# wrap chain1’s string into dict expected by chain2\n",
    "seq_chain = chain1 | RunnableLambda(lambda x: {\"text\": x}) | chain2\n",
    "\n",
    "result = seq_chain.invoke({\"concept\": \"seismic waves\"})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e5c9a1-7a91-486f-b684-0e558ba137b6",
   "metadata": {},
   "source": [
    "# LangChain Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6f1e2e24-8a27-4790-b075-c374ca23c051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Micheal\\n'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "python = PythonREPL()\n",
    "\n",
    "code = \"\"\"\n",
    "age = 16\n",
    "if age > 18:\n",
    "    print(\"Joshua\")\n",
    "else:\n",
    "    print(\"Micheal\")\n",
    "\"\"\"\n",
    "python.run(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f35f49ce-caf9-415c-b292-bd721ba37ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought:\n",
      "The user wants to find the square root of the factorial of 6 million and format the answer to 4 decimal places.\n",
      "\n",
      "1.  **The number is huge**: 6,000,000! is an astronomically large number. Directly calculating it will cause an overflow error in any standard programming language.\n",
      "2.  **Logarithms are the solution**: To handle such large numbers, I must use logarithms. The property `log(a^b) = b * log(a)` is key here.\n",
      "    *   `sqrt(n!) = (n!)^(1/2)`\n",
      "    *   `log(sqrt(n!)) = (1/2) * log(n!)`\n",
      "3.  **Scientific Notation**: The result will also be a very large number. The request to format it to 4 decimal places is ambiguous for a number with millions of digits. The most sensible interpretation is to represent the number in scientific notation (`M x 10^E`) and round the mantissa (`M`) to 4 decimal places.\n",
      "4.  **Using base-10 logarithm**: To get the number in scientific notation, it's best to use the base-10 logarithm (`log10`).\n",
      "    *   `log10(sqrt(n!)) = (1/2) * log10(n!)`\n",
      "5.  **Calculating `log10(n!)`**: A naive sum of `log10(i)` from 1 to n would be slow. A much more efficient and numerically stable way is to use the log-gamma function, `lgamma`, which is available in Python's `math` module. `lgamma(x)` calculates `ln(gamma(x))`.\n",
      "    *   We know that `n! = gamma(n+1)`.\n",
      "    *   Therefore, `ln(n!) = lgamma(n+1)`.\n",
      "    *   To get `log10(n!)`, we can use the change of base formula: `log10(x) = ln(x) / ln(10)`.\n",
      "    *   So, `log10(n!) = lgamma(n+1) / ln(10)`.\n",
      "6.  **Putting it all together**:\n",
      "    *   `log10_sqrt_fact = (1/2) * lgamma(n+1) / ln(10)` where `n = 6,000,000`.\n",
      "    *   The result of this calculation will be a number, let's call it `y`.\n",
      "    *   `y = E + F`, where `E` is the integer part (the exponent of 10) and `F` is the fractional part.\n",
      "    *   The original number is `10^y = 10^(E+F) = 10^F * 10^E`.\n",
      "    *   The mantissa is `M = 10^F`.\n",
      "7.  **Final Steps**:\n",
      "    *   Calculate `log10_sqrt_fact`.\n",
      "    *   Separate the integer part `E` and the fractional part `F`.\n",
      "    *   Calculate the mantissa `M = 10^F`.\n",
      "    *   Round `M` to 4 decimal places.\n",
      "    *   Construct the final answer string in the format `M_rounded x 10^E`.\n",
      "\n",
      "Let's execute the code to perform these steps.\n",
      "Action: Python_REPL\n",
      "Action Input:\n",
      "```python\n",
      "import math\n",
      "\n",
      "n = 6000000\n",
      "\n",
      "# Calculate log10(sqrt(n!)) using the lgamma function for precision and efficiency.\n",
      "# log10(sqrt(n!)) = 0.5 * log10(n!) = 0.5 * (lgamma(n + 1) / log(10))\n",
      "log10_sqrt_fact = (0.5 * math.lgamma(n + 1)) / math.log(10)\n",
      "\n",
      "# The integer part of the result is the exponent in scientific notation.\n",
      "exponent = int(log10_sqrt_fact)\n",
      "\n",
      "# The fractional part is used to calculate the mantissa.\n",
      "# mantissa = 10^(fractional_part)\n",
      "mantissa = 10**(log10_sqrt_fact - exponent)\n",
      "\n",
      "# Round the mantissa to 4 decimal places as requested.\n",
      "rounded_mantissa = round(mantissa, 4)\n",
      "\n",
      "# Format the final answer in scientific notation.\n",
      "final_answer = f\"{rounded_mantissa} x 10^{exponent}\"\n",
      "print(final_answer)\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1.5832 x 10^19031572\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 1.5832 x 10^19031572\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the square root of the factorial of 6 million, return ans in 4 d.p',\n",
       " 'output': '1.5832 x 10^19031572'}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "chat_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "python_tool = PythonREPLTool()\n",
    "\n",
    "agent = create_python_agent(\n",
    "    llm=chat_llm,\n",
    "    tool=python_tool,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent.invoke(\"What is the square root of the factorial of 6 million, return ans in 4 d.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "85986eb7-dbfe-4672-849c-1d96c5e91c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to calculate the value of 5.1 raised to the power of 7.356. I can use the Python REPL for this calculation.\n",
      "Action: Python_REPL\n",
      "Action Input: print(5.1 ** 7.356)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m160282.5397378007\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I need to calculate the value of 5.1 raised to the power of 7.356. I can use the Python REPL for this calculation.\n",
      "Action: Python_REPL\n",
      "Action Input: print(5.1 ** 7.356)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m160282.5397378007\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 160282.5397378007\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is 5.1 ** 7.356', 'output': '160282.5397378007'}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"What is 5.1 ** 7.356\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5f3089-5442-4f94-b852-9045c196f6d6",
   "metadata": {},
   "source": [
    "# LangChain Tools: DuckDuckGo & Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ab1948f0-b8c7-46ee-aba6-0e17ae26266e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of presidents of the United StatesThe White House, official residence of the president of the United States The president of the United States is the head of state and head of government of … The president -elect of the United States is the candidate who has won the United States presidential election and is awaiting inauguration to become ... The president of the United States ( POTUS ) B is the head of state and head of government of the United States . ... the later office of president of ... Donald Trump became America’s 47th president after mounting the most momentous comeback in political history that handed him massive, disruptive power at home and sent shockwaves around … President Donald J. Trump and Vice President JD Vance are committed to lowering costs for all Americans, securing our borders, unleashing American energy dominance, restoring peace …\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search_engine = DuckDuckGoSearchRun()\n",
    "\n",
    "output = search_engine.invoke(\"Who is the President of the United States of America?\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "17fe6152-f0ac-4566-b1c4-e4761f3b7c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snippet: The president of the United States is the head of state and head of government of the United States , [1] indirectly elected to a four-year term via the Electoral College. [2] See full list on en.wikipedia.org View all presidency of the United States of America, chief executive office of the United States . In contrast to many countries with parliamentary forms of government, where the office of president, or head of state, is mainly ceremonial, in the United States the president is vested with great authority and is arguably the most powerful elected official in ... See full list on britannica.com The Constitution succinctly defines presidential functions, powers, and responsibilities. The president ’s chief duty is to make sure that the laws are faithfully executed, and this duty is performed through an elaborate system of executive agencies that includes cabinet-level departments. Presidents appoint all cabinet heads and most other high-ran... See full list on britannica.com Jul 31, 2025 · Learn about the duties of the U . S . president , vice president , and first lady. Find out how to contact and learn more about current and past leaders. Apr 15, 2025 · And what does his return mean for the future of the United States ? Take a closer look at the current president ’s background, political rise, major accomplishments, and what’s next for his second term in office. Jan 20, 2025 · Donald Trump is sworn in as the 47th US President in the US Capitol Rotunda in Washington, DC, on January 20, 2025. Reuters. Donald Trump is now President Donald Trump – the head of the state and the head of the government of the United States of America . Who is the current president of the United States? The incumbent president is Joe Biden , who assumed office on January 20, 2021. The president of the United States is the head of state and head of government of the United States, indirectly elected to a four-year term via the Electoral College. How many terms does a president have? The president is indirectly elected to a five-year term and is limited to a maximum of two terms , as specified by the Constitution. As in most parliamentary systems, the president is now by-and-large a ceremonial office, with the prime minister de facto heading the executive branch. Who elected a president of the United States in Congress? The members of Congress elected a president of the United States in Congress Assembled to preside over its deliberation as a neutral discussion moderator. Unrelated to and quite dissimilar from the later office of president of the United States, it was a largely ceremonial position without much influence. Learn more about the Presidents of the United States ., title: List of presidents of the United States - Wikipedia Images Presidency of the United States of America | History ... Presidents, vice presidents, and first ladies - USAGov Who Is The President Of The USA? - All About America Donald Trump becomes president of the United States for a ... List of presidents of the United States - Wikiwand List of heads of state of Albania - Wikiwand President of the United States - Wikipedia Presidents | The White House, link: https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States, snippet: For a list of presidents of the United States , see List of presidents of the United States . ... the later office of president of the United States ..., title: President of the United States - Wikipedia, link: https://en.wikipedia.org/wiki/President_of_the_United_States, snippet: While at Harvard, Roosevelt began a systematic study of the role played by the United States Navy in the War of 1812 ., title: Theodore Roosevelt - Wikipedia, link: https://en.wikipedia.org/wiki/Theodore_Roosevelt, snippet: amazon.com has been visited by 1M+ users in the past month Discover the Americas' diverse cultural heritage. Your next best read awaits at Amazon. Discover rich history of North & South America . Huge selection & great prices at Amazon., title: All Presidents Of Usa History - Explore All Presidents Of Usa Books, link: https://www.bing.com/aclick?ld=e8Ktq5tctsMTeTojBEHxS2djVUCUzuJ_Q1VNn9UJjoX9o0e-ltvHS0U6TRqzpiPIfNz8AU9j5XXzfyRP-Cvv2jN1-wvv7CP6vqTEks_MGtmKhpbAgC_YdfaN97ilkCUViU7L___HdqjE3-NkZkSKIoxtp2EC5FD6GpnK7sVx3CtVuLu1F863w_lXrFL9DAHE890ex7Ug&u=aHR0cHMlM2ElMmYlMmZ3d3cuYW1hem9uLmNvbSUyZnMlMmYlM2ZpZSUzZFVURjglMjZrZXl3b3JkcyUzZGFsbCUyYnByZXNpZGVudHMlMmJvZiUyYnVzYSUyNmluZGV4JTNkYXBzJTI2dGFnJTNkbWgwYi0yMCUyNnJlZiUzZHBkX3NsX21ibXM4ZHdmMV9lJTI2YWRncnBpZCUzZDEzNDQ3MDUyNDY3OTE4MDUlMjZodmFkaWQlM2Q4NDA0NDM1NTA4MzQ4OCUyNmh2bmV0dyUzZG8lMjZodnFtdCUzZGUlMjZodmJtdCUzZGJlJTI2aHZkZXYlM2RjJTI2aHZsb2NpbnQlM2QxOTAlMjZodmxvY3BoeSUzZDE0MjY4MSUyNmh2dGFyZ2lkJTNka3dkLTg0MDQ1MjUyMDI0NTQ2JTNhbG9jLTE5MCUyNmh5ZGFkY3IlM2QyMDQwOF8xMzYwNzY4NCUyNm1jaWQlM2Q0YjE5M2MyNTE0M2UzMWNmYTc3OGU4ZDdjYmQ4OTcxMyUyNm1zY2xraWQlM2Q2ZjJiMWJkZjNlZDYxNTg0Y2RjNDczMTBlZjIzNzRiNA&rlid=6f2b1bdf3ed61584cdc47310ef2374b4\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "\n",
    "search = DuckDuckGoSearchResults()\n",
    "response = search.run(\"President of the United States of America\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b61f2131-e56d-4407-8fc3-79cbbcf607fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snippet: The White House, official residence of the president of the United States The president of the United States is the head of state and head of government of the United States , [1] indirectly elected to a four-year term via the Electoral College. [2] Under the U.S. Constitution, the officeholder leads the executive branch of the federal government and is the commander-in-chief of the United ..., title: List of presidents of the United States - Wikipedia, link: https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States, snippet: Apr 15, 2025 · As of 2025, the President of the United States is Donald J. Trump, a real estate mogul, television personality, and political outsider who reshaped modern American politics., title: Who Is The President Of The USA? - All About America, link: https://allaboutamerica.com/united-states/who-is-the-president-of-the-usa.html, snippet: Nov 6, 2024 · WASHINGTON (AP) — Donald Trump was elected the 47th president of the United States on Wednesday, an extraordinary comeback for a former president who refused to accept defeat four years..., title: Donald Trump elected 47th president of the United States - PBS, link: https://www.pbs.org/newshour/politics/donald-trump-elected-47th-president-of-the-united-states, snippet: Jul 31, 2025 · Learn about the duties of the U . S . president , vice president , and first lady. Find out how to contact and learn more about current and past leaders., title: Presidents, vice presidents, and first ladies - USAGov, link: https://www.usa.gov/presidents\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "wrapper = DuckDuckGoSearchAPIWrapper(max_results=3, safesearch=\"moderate\")\n",
    "search = DuckDuckGoSearchResults(api_wrapper=wrapper, source='news')\n",
    "output = search.run(\"Who is the President of the United States of America\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1418151a-43b8-4969-b546-142432755d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c3b6d152-efcc-406b-be58-d4c0e5f183db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: Charlie Kirk\n",
      "Summary: Charles James Kirk (October 14, 1993 – September 10, 2025) was an American right-wing political activist, entrepreneur, and media personality. He co-founded the conservative organization Turning Point USA (TPUSA) in 2012 and was its executive director. He published a range of books and hosted The Charlie Kirk Show, a talk radio program. Kirk became recognized as one of the most prominent voices of the MAGA movement in the Republican Party and, since his assassination, has been considered an icon of modern American conservatism.\n",
      "Kirk was born and raised in the Chicago suburbs of Arlington Heights and Prospect Heights, briefly attending Harper College before dropping out after one semester to pursue political activism full-time. He worked with various donors to fund TPUSA, rising to prominence via informal college campus debates held at his signature \"Prove Me Wrong\" table. He extended TPUSA's influence through initiatives such as the Professor Watchlist and mass rallies aimed at young voters, and has since been credited with generating interest in political conservatism among American youth. Under Kirk's leadership, TPUSA developed several affiliate groups, including Turning Point Action and Turning Point Faith, with the latter aimed at mobilizing religious communities around conservative issues. Partnering with Pentecostal pastor Rob McCoy in creating Turning Point Faith, Kirk became aligned with the Christian right and advocated for Christian nationalism.\n",
      "A key ally of Donald Trump, Kirk espoused a variety of conservative stances, including opposition to abortion, gun control, DEI programs, and LGBT rights. His more controversial views included his criticism of the Civil Rights Act of 1964 and Martin Luther King Jr., as well as his promotion of COVID-19 misinformation, false claims of electoral fraud in 2020, and the Great Replacement conspiracy theory. \n",
      "On September 10, 2025, Kirk was assassinated while speaking at a TPUSA public debate event on the Utah Valley University campus. His death gained international attention and led to the condemnation of political violence by prominent domestic and international figures. Trump announced that Kirk would posthumously receive the Presidential Medal of Freedom.\n"
     ]
    }
   ],
   "source": [
    "wiki_wrapper = WikipediaAPIWrapper(top_k_results=1, docs_content_chars_max=500)\n",
    "wiki = WikipediaQueryRun(api_wrapper=wiki_wrapper)\n",
    "\n",
    "print(wiki.invoke({\"query\":\"Charlie Kirk\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "977a8b41-21da-49ce-a1e8-77731d24056e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: Bola Tinubu\n",
      "Summary: Asiwaju Bola Ahmed Adekunle Tinubu  (born 29 March 1952) is a Nigerian politician serving as the 16th and current president of Nigeria since 2023. He previously served as the governor of Lagos State from 1999 to 2007, and senator for Lagos West in the Third Republic.\n",
      "Tinubu spent his early life in southwestern Nigeria and later moved to the United States where he studied accounting at Chicago State University. He returned to Nigeria in the 1980s and was employed by Mobil Nigeria as an accountant, before entering politics as a Lagos West senatorial candidate in 1992 under the banner of the Social Democratic Party. After the military dictator Sani Abacha dissolved the Senate in 1993, Tinubu went into exile and became an activist campaigning for the return of democracy as a part of the National Democratic Coalition movement.\n",
      "In the first post-transition Lagos State gubernatorial election, Tinubu won by a wide margin as a member of the Alliance for Democracy. Four years later, he won re-election to a second term. After leaving office in 2007, he played a key role in forming the All Progressives Congress in 2013. In 2023, he was elected president, defeating Atiku Abubakar and Peter Obi.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(wiki.invoke(\"Bola Tinubu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d36702-c832-468e-9ddf-c015144a1527",
   "metadata": {},
   "source": [
    "# ReaAct Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5e92d468-3cc3-49b5-95ca-bfc2e7798a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import hub\n",
    "from langchain.agents import Tool, AgentExecutor, create_react_agent, initialize_agent\n",
    "from langchain.tools import DuckDuckGoSearchRun, WikipediaQueryRun\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "chat_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the following questions as best you can.\n",
    "Questions {q}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "# print(type(prompt)) <class 'langchain_core.prompts.prompt.PromptTemplate'>\n",
    "\n",
    "# tool 1 - Python\n",
    "python_repl = PythonREPLTool()\n",
    "python_repl_tool = Tool(\n",
    "    name='Python REPL',\n",
    "    func=python_repl.run,\n",
    "    description='Useful when you need to perform computations and calculations'\n",
    ")\n",
    "\n",
    "# tool 2 - Wikipedia\n",
    "api_wrapper = WikipediaAPIWrapper()\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "wikipedia_tool = Tool(\n",
    "    name='Wikipedia Tool',\n",
    "    func=wikipedia.run,\n",
    "    description='Useful for looking up information on Wikipedia'\n",
    ")\n",
    "\n",
    "# tool 3 - DuckDuckGo\n",
    "search = DuckDuckGoSearchRun()\n",
    "search_tool = Tool(\n",
    "    name='DuckDuckGoSearchRun',\n",
    "    func=search.run,\n",
    "    description='Useful for internet search and for information other tools can\\'t provide'\n",
    ")\n",
    "\n",
    "\n",
    "tools = [python_repl_tool, wikipedia_tool, search_tool]\n",
    "\n",
    "# create react agent\n",
    "agent = create_react_agent(chat_llm, tools, prompt)\n",
    "\n",
    "# setup agent executor \n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ed11d22f-df68-48c9-b07d-f3944a541866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought\n",
      "The user wants to generate the first 20 numbers in the Fibonacci sequence. I can write a Python script to do this. The Fibonacci sequence starts with 0 and 1, and each subsequent number is the sum of the two preceding ones. I will use the Python REPL tool to execute the code.\n",
      "Action:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Python REPL\",\n",
      "  \"action_input\": \"def fibonacci(n):\\n    series = []\\n    a, b = 0, 1\\n    while len(series) < n:\\n        series.append(a)\\n        a, b = b, a + b\\n    return series\\n\\nprint(fibonacci(20))\"\n",
      "}\n",
      "```\u001b[0mInvalid Format: Missing 'Action Input:' after 'Action:'\u001b[32;1m\u001b[1;3mThought: The user wants to generate the first 20 numbers in the Fibonacci sequence. I can write a Python script to do this. I will use a loop to generate the numbers and store them in a list. Then I will print the list.\n",
      "Action: Python REPL\n",
      "Action Input: a, b = 0, 1\n",
      "fib_list = []\n",
      "for _ in range(20):\n",
      "    fib_list.append(a)\n",
      "    a, b = b, a + b\n",
      "print(fib_list)\u001b[0m\u001b[36;1m\u001b[1;3m[0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181]\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The first 20 numbers in the Fibonacci Series are: 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "question = \"Generate first 20 numbers in the Fibonacci Series\"\n",
    "\n",
    "output = agent_executor.invoke({\n",
    "    'input': prompt_template.format(q=question)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3a89fad0-307e-4810-b1bf-f0f106524545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the following questions as best you can.\n",
      "Questions Generate first 20 numbers in the Fibonacci Series\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ff0ca877-1a95-4251-bc35-d0df54250771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 20 numbers in the Fibonacci Series are: 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181.\n"
     ]
    }
   ],
   "source": [
    "print(output['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a28bc8a3-d49f-4093-b3f1-8dff47f894f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to answer the question \"Who is Donald Trump?\" in a single sentence and in French.\n",
      "\n",
      "First, I will formulate the answer in English. A good, neutral, one-sentence summary would be: \"Donald Trump is an American politician, media personality, and businessman who served as the 45th president of the United States from 2017 to 2021.\"\n",
      "\n",
      "Now, I will translate this sentence into French.\n",
      "- \"Donald Trump is\" -> \"Donald Trump est\"\n",
      "- \"an American politician\" -> \"un homme politique américain\"\n",
      "- \"media personality\" -> \"une personnalité médiatique\"\n",
      "- \"and businessman\" -> \"et un homme d'affaires\"\n",
      "- \"who served as the 45th president of the United States\" -> \"qui a été le 45e président des États-Unis\"\n",
      "- \"from 2017 to 2021\" -> \"de 2017 à 2021\"\n",
      "\n",
      "Combining these parts gives: \"Donald Trump est un homme politique, une personnalité médiatique et un homme d'affaires américain qui a été le 45e président des États-Unis de 2017 à 2021.\"\n",
      "\n",
      "This is a single, accurate sentence in French. I am confident in this translation and don't need to use any external tools.\n",
      "\n",
      "Final Answer: Donald Trump est un homme d'affaires, une personnalité médiatique et un homme politique américain qui a été le 45e président des États-Unis de 2017 à 2021.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "question = \"Who is Donald Trump. Answer in French in one sentence?\"\n",
    "\n",
    "output = agent_executor.invoke({\n",
    "    'input': prompt_template.format(q=question)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e10c1f71-654e-4e91-b576-88c0edcd1ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald Trump est un homme d'affaires, une personnalité médiatique et un homme politique américain qui a été le 45e président des États-Unis de 2017 à 2021.\n"
     ]
    }
   ],
   "source": [
    "print(output['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19949c4-440c-4a79-a361-5028790a9ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080738cb-3dce-4e0d-b102-749092abf287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1acd36-3aba-42fe-89c1-5ef7b08cfcf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai-engine)",
   "language": "python",
   "name": "ai-engine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
